{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xYpLqbfUn6ER",
        "outputId": "00980842-bd5e-4a86-a2b1-e5d3ea184f39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Найдено компаний: 0\n",
            "Собрано данных о 0 компаниях\n"
          ]
        }
      ],
      "source": [
        "import aiohttp\n",
        "import asyncio\n",
        "import json\n",
        "import nest_asyncio\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List, Dict\n",
        "\n",
        "SP500_URL = \"https://markets.businessinsider.com/index/components/s&p_500\"\n",
        "CBR_URL = \"https://www.cbr.ru/scripts/XML_daily.asp\"\n",
        "\n",
        "async def fetch(session: aiohttp.ClientSession, url: str) -> str:\n",
        "    async with session.get(url) as response:\n",
        "        return await response.text()\n",
        "\n",
        "async def get_usd_to_rub(session: aiohttp.ClientSession) -> float:\n",
        "    xml_data = await fetch(session, CBR_URL)\n",
        "    soup = BeautifulSoup(xml_data, 'xml')\n",
        "    usd_rate_element = soup.find(\"Valute\", {'ID': 'R01235'})\n",
        "    if usd_rate_element:\n",
        "        usd_rate = usd_rate_element.find(\"Value\").text.replace(',', '.')\n",
        "        return float(usd_rate)\n",
        "    return 0.0\n",
        "\n",
        "async def get_sp500_companies(session: aiohttp.ClientSession) -> List[Dict[str, str]]:\n",
        "\n",
        "    html = await fetch(session, SP500_URL)\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    rows = soup.select(\".table__tr\")\n",
        "    companies = []\n",
        "\n",
        "\n",
        "    for row in rows[1:]:\n",
        "        cols = row.select(\".table__td\")\n",
        "        if len(cols) < 5:\n",
        "            continue\n",
        "        name = cols[0].text.strip()\n",
        "        url = cols[0].find(\"a\")[\"href\"]\n",
        "        try:\n",
        "            growth = float(cols[4].text.strip().replace('%', '').replace(',', '.'))\n",
        "        except ValueError:\n",
        "            growth = 0.0\n",
        "        companies.append({\"name\": name, \"url\": url, \"growth\": growth})\n",
        "\n",
        "    print(f\"Найдено компаний: {len(companies)}\")\n",
        "    return companies\n",
        "\n",
        "async def get_company_data(session: aiohttp.ClientSession, company: Dict[str, str], usd_to_rub: float) -> Dict:\n",
        "    html = await fetch(session, \"https://markets.businessinsider.com\" + company[\"url\"])\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "    try:\n",
        "        code_element = soup.select_one(\".price-section__category\")\n",
        "        price_element = soup.select_one(\".price-section__current-value\")\n",
        "        pe_element = soup.find(text=\"P/E Ratio\")\n",
        "        low_52_element = soup.find(text=\"52 Week Low\")\n",
        "        high_52_element = soup.find(text=\"52 Week High\")\n",
        "\n",
        "        code = code_element.text.split(\" \")[-1] if code_element else \"N/A\"\n",
        "        price = float(price_element.text.replace(',', '')) * usd_to_rub if price_element else 0.0\n",
        "        pe = float(pe_element.find_next().text.replace(',', '')) if pe_element else None\n",
        "        low_52 = float(low_52_element.find_next().text.replace(',', '')) if low_52_element else 0.0\n",
        "        high_52 = float(high_52_element.find_next().text.replace(',', '')) if high_52_element else 0.0\n",
        "        potential_profit = ((high_52 - low_52) / low_52) * 100 if low_52 > 0 else 0.0\n",
        "    except AttributeError:\n",
        "        print(f\"Ошибка при парсинге компании {company['name']}\")\n",
        "        return {}\n",
        "\n",
        "    return {\n",
        "        \"code\": code,\n",
        "        \"name\": company[\"name\"],\n",
        "        \"price\": price,\n",
        "        \"P/E\": pe,\n",
        "        \"growth\": company[\"growth\"],\n",
        "        \"potential profit\": potential_profit\n",
        "    }\n",
        "\n",
        "async def main():\n",
        "    async with aiohttp.ClientSession() as session:\n",
        "        usd_to_rub = await get_usd_to_rub(session)\n",
        "        if usd_to_rub == 0.0:\n",
        "            print(\"ошибка\")\n",
        "            return\n",
        "\n",
        "        companies = await get_sp500_companies(session)\n",
        "        tasks = [get_company_data(session, company, usd_to_rub) for company in companies]\n",
        "        data = await asyncio.gather(*tasks)\n",
        "        data = [d for d in data if d]\n",
        "\n",
        "        print(f\"Собрано данных о {len(data)} компаниях\")\n",
        "        if data:\n",
        "            print(\"Пример данных:\", data[0])\n",
        "\n",
        "        with open(\"top_price.json\", \"w\") as f:\n",
        "            json.dump(sorted(data, key=lambda x: x[\"price\"], reverse=True)[:10], f, indent=4)\n",
        "        with open(\"top_pe.json\", \"w\") as f:\n",
        "            json.dump(sorted(data, key=lambda x: x[\"P/E\"])[:10], f, indent=4)\n",
        "        with open(\"top_growth.json\", \"w\") as f:\n",
        "            json.dump(sorted(data, key=lambda x: x[\"growth\"], reverse=True)[:10], f, indent=4)\n",
        "        with open(\"top_potential.json\", \"w\") as f:\n",
        "            json.dump(sorted(data, key=lambda x: x[\"potential profit\"], reverse=True)[:10], f, indent=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    nest_asyncio.apply()\n",
        "    asyncio.get_event_loop().run_until_complete(main())"
      ]
    }
  ]
}